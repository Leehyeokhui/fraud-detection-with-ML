{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "- outlier 제거 및 oversampling, undersampling 이용\n",
    "- class = 1 에서 강한 상관관계를 갖는 변수만 사용해 분석 진행(V1 ~ V12, V14, V16 ~ V22) \n",
    "- 나머지는 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V15  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169  1.468177   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.635558   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946  2.345865   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -0.631418   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670  0.175121   \n",
       "\n",
       "        V16       V17       V18       V19       V20       V21       V22  Class  \n",
       "0 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838      0  \n",
       "1  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672      0  \n",
       "2 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679      0  \n",
       "3 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274      0  \n",
       "4 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v = df.drop(['Time', 'V13', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'], axis=1)\n",
    "df_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outlier(data):\n",
    "    for column in data.columns[:-1]: #target column 제외\n",
    "        q25, q75 = np.quantile(data[column], 0.25), np.quantile(data[column], 0.75)\n",
    "        iqr = q75 - q25\n",
    "        lower, upper = q25 - iqr*1.5, q75 + iqr*1.5\n",
    "        \n",
    "        df_no = data[data[column] > lower]\n",
    "        df_no = df_no[df_no[column] < upper]\n",
    "        df_no.reset_index(drop=True)\n",
    "        \n",
    "    return df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V15  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.311169  1.468177   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.635558   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084 -0.165946  2.345865   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -0.631418   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196 -1.119670  0.175121   \n",
       "\n",
       "        V16       V17       V18       V19       V20       V21       V22  Class  \n",
       "0 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838      0  \n",
       "1  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672      0  \n",
       "2 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679      0  \n",
       "3 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274      0  \n",
       "4 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo = drop_outlier(df_v)\n",
    "df_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    283026\n",
       "1       464\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo['Class'].value_counts()\n",
    "# outlier 제거 시 class=1이 이전에 비해 덜 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "      <td>283490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.009914</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.001637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.887156</td>\n",
       "      <td>1.547490</td>\n",
       "      <td>1.486556</td>\n",
       "      <td>1.406641</td>\n",
       "      <td>1.336316</td>\n",
       "      <td>1.307465</td>\n",
       "      <td>1.139677</td>\n",
       "      <td>0.959358</td>\n",
       "      <td>1.093113</td>\n",
       "      <td>1.071210</td>\n",
       "      <td>1.019281</td>\n",
       "      <td>0.993357</td>\n",
       "      <td>0.950670</td>\n",
       "      <td>0.913537</td>\n",
       "      <td>0.871147</td>\n",
       "      <td>0.841260</td>\n",
       "      <td>0.835790</td>\n",
       "      <td>0.811539</td>\n",
       "      <td>0.692761</td>\n",
       "      <td>0.538849</td>\n",
       "      <td>0.693767</td>\n",
       "      <td>0.040424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-34.535000</td>\n",
       "      <td>-9.283925</td>\n",
       "      <td>-18.271168</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-4.391307</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-4.932733</td>\n",
       "      <td>-28.009635</td>\n",
       "      <td>-11.263235</td>\n",
       "      <td>-2.147970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.911114</td>\n",
       "      <td>-0.597661</td>\n",
       "      <td>-0.881447</td>\n",
       "      <td>-0.847413</td>\n",
       "      <td>-0.688505</td>\n",
       "      <td>-0.769414</td>\n",
       "      <td>-0.548962</td>\n",
       "      <td>-0.205725</td>\n",
       "      <td>-0.641554</td>\n",
       "      <td>-0.534484</td>\n",
       "      <td>-0.761254</td>\n",
       "      <td>-0.406558</td>\n",
       "      <td>-0.426436</td>\n",
       "      <td>-0.581822</td>\n",
       "      <td>-0.467345</td>\n",
       "      <td>-0.484764</td>\n",
       "      <td>-0.498565</td>\n",
       "      <td>-0.454570</td>\n",
       "      <td>-0.210548</td>\n",
       "      <td>-0.228147</td>\n",
       "      <td>-0.537982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.026714</td>\n",
       "      <td>0.063979</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>-0.053302</td>\n",
       "      <td>-0.277172</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>-0.051350</td>\n",
       "      <td>-0.093334</td>\n",
       "      <td>-0.031315</td>\n",
       "      <td>0.138486</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.065970</td>\n",
       "      <td>-0.067323</td>\n",
       "      <td>-0.004450</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>-0.062112</td>\n",
       "      <td>-0.029980</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.317413</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>1.030384</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.611356</td>\n",
       "      <td>0.389629</td>\n",
       "      <td>0.571003</td>\n",
       "      <td>0.328710</td>\n",
       "      <td>0.596322</td>\n",
       "      <td>0.451001</td>\n",
       "      <td>0.740057</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.490579</td>\n",
       "      <td>0.648963</td>\n",
       "      <td>0.522189</td>\n",
       "      <td>0.397008</td>\n",
       "      <td>0.499575</td>\n",
       "      <td>0.459213</td>\n",
       "      <td>0.132641</td>\n",
       "      <td>0.184563</td>\n",
       "      <td>0.528011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.454930</td>\n",
       "      <td>18.902453</td>\n",
       "      <td>4.187811</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>23.917837</td>\n",
       "      <td>44.054461</td>\n",
       "      <td>18.748872</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>15.331742</td>\n",
       "      <td>12.018913</td>\n",
       "      <td>4.318071</td>\n",
       "      <td>7.692209</td>\n",
       "      <td>5.784514</td>\n",
       "      <td>8.289890</td>\n",
       "      <td>9.253526</td>\n",
       "      <td>4.295648</td>\n",
       "      <td>5.572113</td>\n",
       "      <td>23.643417</td>\n",
       "      <td>10.378272</td>\n",
       "      <td>2.133863</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count  283490.000000  283490.000000  283490.000000  283490.000000   \n",
       "mean        0.022847       0.002753       0.010282      -0.002163   \n",
       "std         1.887156       1.547490       1.486556       1.406641   \n",
       "min       -56.407510     -72.715728     -33.680984      -5.683171   \n",
       "25%        -0.911114      -0.597661      -0.881447      -0.847413   \n",
       "50%         0.026714       0.063979       0.184485      -0.019039   \n",
       "75%         1.317413       0.798279       1.030384       0.741952   \n",
       "max         2.454930      18.902453       4.187811      16.491217   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count  283490.000000  283490.000000  283490.000000  283490.000000   \n",
       "mean        0.002810      -0.006775       0.011929       0.032275   \n",
       "std         1.336316       1.307465       1.139677       0.959358   \n",
       "min       -42.147898     -26.160506     -26.548144     -34.535000   \n",
       "25%        -0.688505      -0.769414      -0.548962      -0.205725   \n",
       "50%        -0.053302      -0.277172       0.042061       0.023922   \n",
       "75%         0.611356       0.389629       0.571003       0.328710   \n",
       "max        34.801666      23.917837      44.054461      18.748872   \n",
       "\n",
       "                  V9            V10            V11            V12  \\\n",
       "count  283490.000000  283490.000000  283490.000000  283490.000000   \n",
       "mean        0.000628       0.001577       0.000756      -0.002151   \n",
       "std         1.093113       1.071210       1.019281       0.993357   \n",
       "min        -9.283925     -18.271168      -4.797473     -18.683715   \n",
       "25%        -0.641554      -0.534484      -0.761254      -0.406558   \n",
       "50%        -0.051350      -0.093334      -0.031315       0.138486   \n",
       "75%         0.596322       0.451001       0.740057       0.615702   \n",
       "max        10.392889      15.331742      12.018913       4.318071   \n",
       "\n",
       "                 V14            V15            V16            V17  \\\n",
       "count  283490.000000  283490.000000  283490.000000  283490.000000   \n",
       "mean       -0.003406       0.000659      -0.000530      -0.001475   \n",
       "std         0.950670       0.913537       0.871147       0.841260   \n",
       "min       -19.214325      -4.391307     -14.129855     -25.162799   \n",
       "25%        -0.426436      -0.581822      -0.467345      -0.484764   \n",
       "50%         0.048925       0.048681       0.065970      -0.067323   \n",
       "75%         0.490579       0.648963       0.522189       0.397008   \n",
       "max         7.692209       5.784514       8.289890       9.253526   \n",
       "\n",
       "                 V18            V19            V20            V21  \\\n",
       "count  283490.000000  283490.000000  283490.000000  283490.000000   \n",
       "mean       -0.000192       0.000946       0.000783      -0.009914   \n",
       "std         0.835790       0.811539       0.692761       0.538849   \n",
       "min        -9.498746      -4.932733     -28.009635     -11.263235   \n",
       "25%        -0.498565      -0.454570      -0.210548      -0.228147   \n",
       "50%        -0.004450       0.004742      -0.062112      -0.029980   \n",
       "75%         0.499575       0.459213       0.132641       0.184563   \n",
       "max         4.295648       5.572113      23.643417      10.378272   \n",
       "\n",
       "                 V22          Class  \n",
       "count  283490.000000  283490.000000  \n",
       "mean        0.005920       0.001637  \n",
       "std         0.693767       0.040424  \n",
       "min        -2.147970       0.000000  \n",
       "25%        -0.537982       0.000000  \n",
       "50%         0.008451       0.000000  \n",
       "75%         0.528011       0.000000  \n",
       "max         2.133863       1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo.describe()\n",
    "# class=1일 때 상관관계가 낮은 변수들이 outlier의 대부분을 차지하고 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.091799</td>\n",
       "      <td>-0.767442</td>\n",
       "      <td>-1.195123</td>\n",
       "      <td>-0.754119</td>\n",
       "      <td>-0.632621</td>\n",
       "      <td>-0.325355</td>\n",
       "      <td>-1.091859</td>\n",
       "      <td>0.125028</td>\n",
       "      <td>-0.120063</td>\n",
       "      <td>0.253358</td>\n",
       "      <td>1.314819</td>\n",
       "      <td>-0.403043</td>\n",
       "      <td>-1.797417</td>\n",
       "      <td>-0.214560</td>\n",
       "      <td>1.848811</td>\n",
       "      <td>1.202086</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>0.424030</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.286668</td>\n",
       "      <td>0.820654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.080972</td>\n",
       "      <td>-0.978301</td>\n",
       "      <td>-0.858798</td>\n",
       "      <td>-0.504128</td>\n",
       "      <td>-0.872309</td>\n",
       "      <td>-0.393714</td>\n",
       "      <td>-0.788675</td>\n",
       "      <td>-0.004609</td>\n",
       "      <td>-0.241086</td>\n",
       "      <td>1.045959</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.291787</td>\n",
       "      <td>-0.397538</td>\n",
       "      <td>-1.007724</td>\n",
       "      <td>-0.472184</td>\n",
       "      <td>1.717649</td>\n",
       "      <td>-0.406685</td>\n",
       "      <td>-0.604898</td>\n",
       "      <td>-0.337934</td>\n",
       "      <td>-0.477585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.835629</td>\n",
       "      <td>1.324078</td>\n",
       "      <td>0.154558</td>\n",
       "      <td>1.130829</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>-1.187229</td>\n",
       "      <td>0.645624</td>\n",
       "      <td>0.307990</td>\n",
       "      <td>-0.686062</td>\n",
       "      <td>-0.680586</td>\n",
       "      <td>-0.522373</td>\n",
       "      <td>-0.782380</td>\n",
       "      <td>-0.154355</td>\n",
       "      <td>1.086110</td>\n",
       "      <td>0.080934</td>\n",
       "      <td>0.973880</td>\n",
       "      <td>0.644019</td>\n",
       "      <td>0.307190</td>\n",
       "      <td>0.121676</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.039153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.687972</td>\n",
       "      <td>1.579214</td>\n",
       "      <td>1.299132</td>\n",
       "      <td>-0.784778</td>\n",
       "      <td>1.265735</td>\n",
       "      <td>0.652041</td>\n",
       "      <td>1.293312</td>\n",
       "      <td>-3.084464</td>\n",
       "      <td>1.496694</td>\n",
       "      <td>2.375033</td>\n",
       "      <td>-0.602206</td>\n",
       "      <td>-0.953167</td>\n",
       "      <td>-1.357924</td>\n",
       "      <td>1.314201</td>\n",
       "      <td>-0.516707</td>\n",
       "      <td>-0.991221</td>\n",
       "      <td>-0.623162</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>0.143391</td>\n",
       "      <td>1.147074</td>\n",
       "      <td>-0.831285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864773</td>\n",
       "      <td>-1.282571</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>-0.446349</td>\n",
       "      <td>-1.398205</td>\n",
       "      <td>-0.847529</td>\n",
       "      <td>-0.224845</td>\n",
       "      <td>-0.296435</td>\n",
       "      <td>-0.888320</td>\n",
       "      <td>0.445532</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.059851</td>\n",
       "      <td>-0.387702</td>\n",
       "      <td>0.817923</td>\n",
       "      <td>1.298895</td>\n",
       "      <td>0.114378</td>\n",
       "      <td>-1.509740</td>\n",
       "      <td>0.426417</td>\n",
       "      <td>0.708836</td>\n",
       "      <td>0.171504</td>\n",
       "      <td>-0.188199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  2.091799 -0.767442 -1.195123 -0.754119 -0.632621 -0.325355 -1.091859   \n",
       "1  2.080972 -0.978301 -0.858798 -0.504128 -0.872309 -0.393714 -0.788675   \n",
       "2 -0.835629  1.324078  0.154558  1.130829  0.057534 -1.187229  0.645624   \n",
       "3 -1.687972  1.579214  1.299132 -0.784778  1.265735  0.652041  1.293312   \n",
       "4  0.864773 -1.282571  0.413900 -0.446349 -1.398205 -0.847529 -0.224845   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V14       V15  \\\n",
       "0  0.125028 -0.120063  0.253358  1.314819 -0.403043 -1.797417 -0.214560   \n",
       "1 -0.004609 -0.241086  1.045959  0.097000  0.016773  0.291787 -0.397538   \n",
       "2  0.307990 -0.686062 -0.680586 -0.522373 -0.782380 -0.154355  1.086110   \n",
       "3 -3.084464  1.496694  2.375033 -0.602206 -0.953167 -1.357924  1.314201   \n",
       "4 -0.296435 -0.888320  0.445532 -0.002370  0.059851 -0.387702  0.817923   \n",
       "\n",
       "        V16       V17       V18       V19       V20       V21       V22  Class  \n",
       "0  1.848811  1.202086  0.054372  0.424030  0.028609  0.286668  0.820654      0  \n",
       "1 -1.007724 -0.472184  1.717649 -0.406685 -0.604898 -0.337934 -0.477585      0  \n",
       "2  0.080934  0.973880  0.644019  0.307190  0.121676  0.064668  0.039153      0  \n",
       "3 -0.516707 -0.991221 -0.623162  0.070026  0.143391  1.147074 -0.831285      0  \n",
       "4  1.298895  0.114378 -1.509740  0.426417  0.708836  0.171504 -0.188199      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled=df_wo.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_shuffled[df_shuffled.columns[:-1]]\n",
    "df_y = df_shuffled[df_shuffled.columns[-1]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_x_scale = scaler.fit_transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.2)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "re_x, re_y = pipeline.fit_resample(df_x_scale, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "      <td>127361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.925199</td>\n",
       "      <td>0.909554</td>\n",
       "      <td>-1.919317</td>\n",
       "      <td>1.394178</td>\n",
       "      <td>-0.910902</td>\n",
       "      <td>-0.546003</td>\n",
       "      <td>-1.815768</td>\n",
       "      <td>0.758355</td>\n",
       "      <td>-1.011036</td>\n",
       "      <td>-2.233050</td>\n",
       "      <td>1.679687</td>\n",
       "      <td>-2.770029</td>\n",
       "      <td>-3.361907</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>-2.074547</td>\n",
       "      <td>-3.484204</td>\n",
       "      <td>-1.151004</td>\n",
       "      <td>0.387773</td>\n",
       "      <td>0.208801</td>\n",
       "      <td>0.559797</td>\n",
       "      <td>0.006697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.397269</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>3.635731</td>\n",
       "      <td>2.151561</td>\n",
       "      <td>2.672181</td>\n",
       "      <td>1.201486</td>\n",
       "      <td>3.883230</td>\n",
       "      <td>2.687728</td>\n",
       "      <td>1.881825</td>\n",
       "      <td>3.716696</td>\n",
       "      <td>2.680501</td>\n",
       "      <td>4.472376</td>\n",
       "      <td>4.853271</td>\n",
       "      <td>0.976149</td>\n",
       "      <td>3.856626</td>\n",
       "      <td>6.815283</td>\n",
       "      <td>2.722489</td>\n",
       "      <td>1.505143</td>\n",
       "      <td>1.090204</td>\n",
       "      <td>1.699027</td>\n",
       "      <td>0.998959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-19.914081</td>\n",
       "      <td>-28.848048</td>\n",
       "      <td>-19.830442</td>\n",
       "      <td>-3.849000</td>\n",
       "      <td>-31.542536</td>\n",
       "      <td>-16.767239</td>\n",
       "      <td>-21.400008</td>\n",
       "      <td>-22.906509</td>\n",
       "      <td>-8.493697</td>\n",
       "      <td>-17.058075</td>\n",
       "      <td>-4.595095</td>\n",
       "      <td>-18.806530</td>\n",
       "      <td>-20.207798</td>\n",
       "      <td>-4.196091</td>\n",
       "      <td>-16.219245</td>\n",
       "      <td>-29.909130</td>\n",
       "      <td>-11.364785</td>\n",
       "      <td>-5.639772</td>\n",
       "      <td>-40.433107</td>\n",
       "      <td>-20.884032</td>\n",
       "      <td>-3.104636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.190608</td>\n",
       "      <td>-0.126045</td>\n",
       "      <td>-2.922344</td>\n",
       "      <td>-0.162681</td>\n",
       "      <td>-1.124512</td>\n",
       "      <td>-1.120571</td>\n",
       "      <td>-2.103194</td>\n",
       "      <td>-0.198585</td>\n",
       "      <td>-1.820911</td>\n",
       "      <td>-3.731790</td>\n",
       "      <td>-0.290239</td>\n",
       "      <td>-4.670872</td>\n",
       "      <td>-6.594597</td>\n",
       "      <td>-0.569738</td>\n",
       "      <td>-3.204077</td>\n",
       "      <td>-5.538532</td>\n",
       "      <td>-1.669245</td>\n",
       "      <td>-0.496577</td>\n",
       "      <td>-0.261107</td>\n",
       "      <td>-0.283766</td>\n",
       "      <td>-0.739485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.325352</td>\n",
       "      <td>0.529967</td>\n",
       "      <td>-0.736136</td>\n",
       "      <td>0.780336</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-0.497999</td>\n",
       "      <td>-0.453257</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>-0.566307</td>\n",
       "      <td>-0.621865</td>\n",
       "      <td>0.889423</td>\n",
       "      <td>-0.583311</td>\n",
       "      <td>-0.751652</td>\n",
       "      <td>0.044509</td>\n",
       "      <td>-0.521778</td>\n",
       "      <td>-0.504994</td>\n",
       "      <td>-0.332486</td>\n",
       "      <td>0.257802</td>\n",
       "      <td>0.036656</td>\n",
       "      <td>0.264940</td>\n",
       "      <td>0.026279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.569407</td>\n",
       "      <td>1.507400</td>\n",
       "      <td>0.303630</td>\n",
       "      <td>2.723456</td>\n",
       "      <td>0.369170</td>\n",
       "      <td>0.017596</td>\n",
       "      <td>0.274831</td>\n",
       "      <td>0.839976</td>\n",
       "      <td>0.186750</td>\n",
       "      <td>0.060016</td>\n",
       "      <td>3.129082</td>\n",
       "      <td>0.281177</td>\n",
       "      <td>0.180219</td>\n",
       "      <td>0.699763</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.343083</td>\n",
       "      <td>0.447021</td>\n",
       "      <td>1.135567</td>\n",
       "      <td>0.537345</td>\n",
       "      <td>1.091344</td>\n",
       "      <td>0.747544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.280426</td>\n",
       "      <td>10.258027</td>\n",
       "      <td>2.810211</td>\n",
       "      <td>9.010788</td>\n",
       "      <td>24.626451</td>\n",
       "      <td>17.236496</td>\n",
       "      <td>32.347337</td>\n",
       "      <td>19.509535</td>\n",
       "      <td>9.434859</td>\n",
       "      <td>12.735980</td>\n",
       "      <td>11.790834</td>\n",
       "      <td>4.143174</td>\n",
       "      <td>6.989771</td>\n",
       "      <td>6.203381</td>\n",
       "      <td>9.516686</td>\n",
       "      <td>8.489777</td>\n",
       "      <td>5.077881</td>\n",
       "      <td>6.441347</td>\n",
       "      <td>15.405576</td>\n",
       "      <td>19.217138</td>\n",
       "      <td>3.066810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count  127361.000000  127361.000000  127361.000000  127361.000000   \n",
       "mean       -0.925199       0.909554      -1.919317       1.394178   \n",
       "std         2.397269       1.925810       3.635731       2.151561   \n",
       "min       -19.914081     -28.848048     -19.830442      -3.849000   \n",
       "25%        -1.190608      -0.126045      -2.922344      -0.162681   \n",
       "50%        -0.325352       0.529967      -0.736136       0.780336   \n",
       "75%         0.569407       1.507400       0.303630       2.723456   \n",
       "max         1.280426      10.258027       2.810211       9.010788   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count  127361.000000  127361.000000  127361.000000  127361.000000   \n",
       "mean       -0.910902      -0.546003      -1.815768       0.758355   \n",
       "std         2.672181       1.201486       3.883230       2.687728   \n",
       "min       -31.542536     -16.767239     -21.400008     -22.906509   \n",
       "25%        -1.124512      -1.120571      -2.103194      -0.198585   \n",
       "50%        -0.268788      -0.497999      -0.453257       0.137428   \n",
       "75%         0.369170       0.017596       0.274831       0.839976   \n",
       "max        24.626451      17.236496      32.347337      19.509535   \n",
       "\n",
       "                  V9            V10            V11            V12  \\\n",
       "count  127361.000000  127361.000000  127361.000000  127361.000000   \n",
       "mean       -1.011036      -2.233050       1.679687      -2.770029   \n",
       "std         1.881825       3.716696       2.680501       4.472376   \n",
       "min        -8.493697     -17.058075      -4.595095     -18.806530   \n",
       "25%        -1.820911      -3.731790      -0.290239      -4.670872   \n",
       "50%        -0.566307      -0.621865       0.889423      -0.583311   \n",
       "75%         0.186750       0.060016       3.129082       0.281177   \n",
       "max         9.434859      12.735980      11.790834       4.143174   \n",
       "\n",
       "                 V14            V15            V16            V17  \\\n",
       "count  127361.000000  127361.000000  127361.000000  127361.000000   \n",
       "mean       -3.361907       0.013651      -2.074547      -3.484204   \n",
       "std         4.853271       0.976149       3.856626       6.815283   \n",
       "min       -20.207798      -4.196091     -16.219245     -29.909130   \n",
       "25%        -6.594597      -0.569738      -3.204077      -5.538532   \n",
       "50%        -0.751652       0.044509      -0.521778      -0.504994   \n",
       "75%         0.180219       0.699763       0.402113       0.343083   \n",
       "max         6.989771       6.203381       9.516686       8.489777   \n",
       "\n",
       "                 V18            V19            V20            V21  \\\n",
       "count  127361.000000  127361.000000  127361.000000  127361.000000   \n",
       "mean       -1.151004       0.387773       0.208801       0.559797   \n",
       "std         2.722489       1.505143       1.090204       1.699027   \n",
       "min       -11.364785      -5.639772     -40.433107     -20.884032   \n",
       "25%        -1.669245      -0.496577      -0.261107      -0.283766   \n",
       "50%        -0.332486       0.257802       0.036656       0.264940   \n",
       "75%         0.447021       1.135567       0.537345       1.091344   \n",
       "max         5.077881       6.441347      15.405576      19.217138   \n",
       "\n",
       "                 V22  \n",
       "count  127361.000000  \n",
       "mean        0.006697  \n",
       "std         0.998959  \n",
       "min        -3.104636  \n",
       "25%        -0.739485  \n",
       "50%         0.026279  \n",
       "75%         0.747544  \n",
       "max         3.066810  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_x = pd.DataFrame(re_x)\n",
    "re_x.columns = df_x.columns\n",
    "\n",
    "re_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0        70756\n",
       "1        56605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_y = pd.DataFrame(re_y)\n",
    "\n",
    "re_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(re_x, re_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "\n",
    "- logstic regression with penalty\n",
    "- decision tree\n",
    "- random forest\n",
    "- adaboost\n",
    "- lightgbmboost\n",
    "- catboost\n",
    "\n",
    "이후 잘 나온 모델 2개로 stacking  \n",
    "최종 모델은 xgboost로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logstic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=42),\n",
       "             param_grid=[{'penalty': ['none', 'l2']},\n",
       "                         {'l1_ratio': [0.5, 0.25, 0.75],\n",
       "                          'penalty': ['elasticnet'], 'solver': ['saga']},\n",
       "                         {'penalty': ['l1'], 'solver': ['saga']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "param_grid = [{'penalty' : ['none', 'l2']},\n",
    "              {'penalty' : ['elasticnet'], 'l1_ratio' : [0.5,0.25,0.75], 'solver' : ['saga']},\n",
    "              {'penalty' : ['l1'], 'solver' : ['saga']}]\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "\n",
    "log_grid = GridSearchCV(log_reg, param_grid, cv=cross_validation, scoring='accuracy')\n",
    "log_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232972</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'penalty': 'none'}</td>\n",
       "      <td>0.945692</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944776</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211236</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'penalty': 'l2'}</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944767</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.610835</td>\n",
       "      <td>0.357781</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'l1_ratio': 0.5, 'penalty': 'elasticnet', 'so...</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944767</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.617815</td>\n",
       "      <td>0.360353</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.25</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'l1_ratio': 0.25, 'penalty': 'elasticnet', 's...</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944767</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.590680</td>\n",
       "      <td>0.377637</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.75</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'l1_ratio': 0.75, 'penalty': 'elasticnet', 's...</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944767</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.571739</td>\n",
       "      <td>0.389317</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945649</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.944774</td>\n",
       "      <td>0.944767</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_penalty  \\\n",
       "0       0.232972      0.008475         0.004387        0.000490          none   \n",
       "1       0.211236      0.008354         0.004186        0.000398            l2   \n",
       "2       2.610835      0.357781         0.003968        0.000012    elasticnet   \n",
       "3       2.617815      0.360353         0.004168        0.000399    elasticnet   \n",
       "4       2.590680      0.377637         0.003578        0.000478    elasticnet   \n",
       "5       2.571739      0.389317         0.003769        0.000399            l1   \n",
       "\n",
       "  param_l1_ratio param_solver  \\\n",
       "0            NaN          NaN   \n",
       "1            NaN          NaN   \n",
       "2            0.5         saga   \n",
       "3           0.25         saga   \n",
       "4           0.75         saga   \n",
       "5            NaN         saga   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0                                {'penalty': 'none'}           0.945692   \n",
       "1                                  {'penalty': 'l2'}           0.945649   \n",
       "2  {'l1_ratio': 0.5, 'penalty': 'elasticnet', 'so...           0.945649   \n",
       "3  {'l1_ratio': 0.25, 'penalty': 'elasticnet', 's...           0.945649   \n",
       "4  {'l1_ratio': 0.75, 'penalty': 'elasticnet', 's...           0.945649   \n",
       "5                {'penalty': 'l1', 'solver': 'saga'}           0.945649   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.945649           0.945125           0.942639           0.944774   \n",
       "1           0.945649           0.945125           0.942639           0.944774   \n",
       "2           0.945649           0.945125           0.942639           0.944774   \n",
       "3           0.945649           0.945125           0.942639           0.944774   \n",
       "4           0.945649           0.945125           0.942639           0.944774   \n",
       "5           0.945649           0.945125           0.942639           0.944774   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.944776        0.001122                1  \n",
       "1         0.944767        0.001115                2  \n",
       "2         0.944767        0.001115                2  \n",
       "3         0.944767        0.001115                2  \n",
       "4         0.944767        0.001115                2  \n",
       "5         0.944767        0.001115                2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_result = pd.DataFrame(log_grid.cv_results_)\n",
    "log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'none'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7008,  144],\n",
       "       [ 579, 5006]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = log_grid.best_estimator_\n",
    "log_y_pred = log_model.predict(x_test)\n",
    "\n",
    "log_cm = confusion_matrix(y_test, log_y_pred)\n",
    "log_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.91083021 0.93399288 0.94653824 0.95395379        nan 0.95267131\n",
      " 0.96909029 0.97631386 0.98231609        nan 0.98671308 0.99115368\n",
      " 0.99203483 0.99199122        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [5, 10, 20],\n",
       "                         'max_features': [1, 5, 10, 20, 25]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "parameter_grid = {'max_depth': [5, 10, 20],\n",
    "                  'max_features': [1, 5, 10, 20, 25]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tree_grid = GridSearchCV(tree, param_grid = parameter_grid,\n",
    "                          cv = cross_validation)\n",
    "\n",
    "tree_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087768</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>4.885583e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 1}</td>\n",
       "      <td>0.900676</td>\n",
       "      <td>0.915115</td>\n",
       "      <td>0.912497</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>0.912755</td>\n",
       "      <td>0.910830</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298206</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>1.202538e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5}</td>\n",
       "      <td>0.934351</td>\n",
       "      <td>0.933653</td>\n",
       "      <td>0.933828</td>\n",
       "      <td>0.934046</td>\n",
       "      <td>0.934087</td>\n",
       "      <td>0.933993</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554913</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>3.999970e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 10}</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.946957</td>\n",
       "      <td>0.946041</td>\n",
       "      <td>0.945387</td>\n",
       "      <td>0.945734</td>\n",
       "      <td>0.946538</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.080513</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>6.245381e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 20}</td>\n",
       "      <td>0.956728</td>\n",
       "      <td>0.951363</td>\n",
       "      <td>0.953282</td>\n",
       "      <td>0.955376</td>\n",
       "      <td>0.953019</td>\n",
       "      <td>0.953954</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022151</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 25}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.126064</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>1.196504e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 1}</td>\n",
       "      <td>0.957863</td>\n",
       "      <td>0.949836</td>\n",
       "      <td>0.959564</td>\n",
       "      <td>0.947088</td>\n",
       "      <td>0.949005</td>\n",
       "      <td>0.952671</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.515018</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>4.009789e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 5}</td>\n",
       "      <td>0.965540</td>\n",
       "      <td>0.962181</td>\n",
       "      <td>0.972083</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>0.973957</td>\n",
       "      <td>0.969090</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.983169</td>\n",
       "      <td>0.026787</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>3.970195e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 10}</td>\n",
       "      <td>0.975921</td>\n",
       "      <td>0.971341</td>\n",
       "      <td>0.978277</td>\n",
       "      <td>0.979455</td>\n",
       "      <td>0.976575</td>\n",
       "      <td>0.976314</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960558</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>3.992807e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 20}</td>\n",
       "      <td>0.984558</td>\n",
       "      <td>0.982116</td>\n",
       "      <td>0.981112</td>\n",
       "      <td>0.981985</td>\n",
       "      <td>0.981809</td>\n",
       "      <td>0.982316</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 25}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.151004</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>4.867573e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 1}</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.987830</td>\n",
       "      <td>0.986739</td>\n",
       "      <td>0.988004</td>\n",
       "      <td>0.986259</td>\n",
       "      <td>0.986713</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.611169</td>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>2.431402e-07</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 5}</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.991450</td>\n",
       "      <td>0.993152</td>\n",
       "      <td>0.990796</td>\n",
       "      <td>0.991154</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.178642</td>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 10}</td>\n",
       "      <td>0.992017</td>\n",
       "      <td>0.993108</td>\n",
       "      <td>0.991450</td>\n",
       "      <td>0.991014</td>\n",
       "      <td>0.992584</td>\n",
       "      <td>0.992035</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.788937</td>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>7.461490e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 20}</td>\n",
       "      <td>0.991581</td>\n",
       "      <td>0.992279</td>\n",
       "      <td>0.991189</td>\n",
       "      <td>0.991668</td>\n",
       "      <td>0.993239</td>\n",
       "      <td>0.991991</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 25}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.087768      0.004677         0.005385    4.885583e-04   \n",
       "1        0.298206      0.004768         0.004987    1.202538e-06   \n",
       "2        0.554913      0.003371         0.004790    3.999970e-04   \n",
       "3        1.080513      0.006787         0.004979    6.245381e-04   \n",
       "4        0.022151      0.001588         0.000000    0.000000e+00   \n",
       "5        0.126064      0.002874         0.006582    1.196504e-03   \n",
       "6        0.515018      0.018848         0.005789    4.009789e-04   \n",
       "7        0.983169      0.026787         0.005780    3.970195e-04   \n",
       "8        1.960558      0.014236         0.005186    3.992807e-04   \n",
       "9        0.020750      0.000412         0.000000    0.000000e+00   \n",
       "10       0.151004      0.008400         0.006580    4.867573e-04   \n",
       "11       0.611169      0.035105         0.005984    2.431402e-07   \n",
       "12       1.178642      0.033757         0.005785    3.989697e-04   \n",
       "13       2.788937      0.144287         0.005785    7.461490e-04   \n",
       "14       0.020944      0.000631         0.000000    0.000000e+00   \n",
       "\n",
       "   param_max_depth param_max_features                                 params  \\\n",
       "0                5                  1    {'max_depth': 5, 'max_features': 1}   \n",
       "1                5                  5    {'max_depth': 5, 'max_features': 5}   \n",
       "2                5                 10   {'max_depth': 5, 'max_features': 10}   \n",
       "3                5                 20   {'max_depth': 5, 'max_features': 20}   \n",
       "4                5                 25   {'max_depth': 5, 'max_features': 25}   \n",
       "5               10                  1   {'max_depth': 10, 'max_features': 1}   \n",
       "6               10                  5   {'max_depth': 10, 'max_features': 5}   \n",
       "7               10                 10  {'max_depth': 10, 'max_features': 10}   \n",
       "8               10                 20  {'max_depth': 10, 'max_features': 20}   \n",
       "9               10                 25  {'max_depth': 10, 'max_features': 25}   \n",
       "10              20                  1   {'max_depth': 20, 'max_features': 1}   \n",
       "11              20                  5   {'max_depth': 20, 'max_features': 5}   \n",
       "12              20                 10  {'max_depth': 20, 'max_features': 10}   \n",
       "13              20                 20  {'max_depth': 20, 'max_features': 20}   \n",
       "14              20                 25  {'max_depth': 20, 'max_features': 25}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.900676           0.915115           0.912497   \n",
       "1            0.934351           0.933653           0.933828   \n",
       "2            0.948571           0.946957           0.946041   \n",
       "3            0.956728           0.951363           0.953282   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.957863           0.949836           0.959564   \n",
       "6            0.965540           0.962181           0.972083   \n",
       "7            0.975921           0.971341           0.978277   \n",
       "8            0.984558           0.982116           0.981112   \n",
       "9                 NaN                NaN                NaN   \n",
       "10           0.984733           0.987830           0.986739   \n",
       "11           0.989618           0.990752           0.991450   \n",
       "12           0.992017           0.993108           0.991450   \n",
       "13           0.991581           0.992279           0.991189   \n",
       "14                NaN                NaN                NaN   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913108           0.912755         0.910830        0.005160   \n",
       "1            0.934046           0.934087         0.933993        0.000238   \n",
       "2            0.945387           0.945734         0.946538        0.001143   \n",
       "3            0.955376           0.953019         0.953954        0.001885   \n",
       "4                 NaN                NaN              NaN             NaN   \n",
       "5            0.947088           0.949005         0.952671        0.005042   \n",
       "6            0.971690           0.973957         0.969090        0.004467   \n",
       "7            0.979455           0.976575         0.976314        0.002781   \n",
       "8            0.981985           0.981809         0.982316        0.001173   \n",
       "9                 NaN                NaN              NaN             NaN   \n",
       "10           0.988004           0.986259         0.986713        0.001187   \n",
       "11           0.993152           0.990796         0.991154        0.001160   \n",
       "12           0.991014           0.992584         0.992035        0.000753   \n",
       "13           0.991668           0.993239         0.991991        0.000715   \n",
       "14                NaN                NaN              NaN             NaN   \n",
       "\n",
       "    rank_test_score  \n",
       "0                12  \n",
       "1                11  \n",
       "2                10  \n",
       "3                 8  \n",
       "4                13  \n",
       "5                 9  \n",
       "6                 7  \n",
       "7                 6  \n",
       "8                 5  \n",
       "9                14  \n",
       "10                4  \n",
       "11                3  \n",
       "12                1  \n",
       "13                2  \n",
       "14               15  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_result = pd.DataFrame(tree_grid.cv_results_)\n",
    "tree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'max_features': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7090,   62],\n",
       "       [  28, 5557]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = tree_grid.best_estimator_\n",
    "tree_y_pred = tree_model.predict(x_test)\n",
    "\n",
    "tree_cm = confusion_matrix(y_test, tree_y_pred)\n",
    "tree_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-ea8bec0b4da8>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest.fit(x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features=20, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=42, n_estimators = 100, max_depth = 5, max_features=20)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7050,  102],\n",
       "       [ 419, 5166]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_y_pred = forest.predict(x_test)\n",
    "\n",
    "forest_cm = confusion_matrix(y_test, forest_y_pred)\n",
    "forest_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7024,  128],\n",
       "       [ 271, 5314]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada.fit(x_train, y_train)\n",
    "ada_y_pred = ada.predict(x_test)\n",
    "\n",
    "ada_cm = confusion_matrix(y_test, ada_y_pred)\n",
    "ada_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightgbmboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7126,   26],\n",
       "       [   4, 5581]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "lgbm.fit(x_train, y_train)\n",
    "lgbm_y_pred = lgbm.predict(x_test)\n",
    "\n",
    "lgbm_cm = confusion_matrix(y_test, lgbm_y_pred)\n",
    "lgbm_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7131,   21],\n",
       "       [   0, 5585]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "cat.fit(x_train, y_train)\n",
    "cat_y_pred = cat.predict(x_test)\n",
    "\n",
    "cat_cm = confusion_matrix(y_test, cat_y_pred)\n",
    "cat_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_score(cm):\n",
    "    accuracy = (cm[0,0] + cm[1,1]) / (cm[0,0]+cm[1,0]+cm[0,1]+cm[1,1])\n",
    "    error_rate = 1-accuracy\n",
    "    specificity = cm[1,1] / (cm[0,1] + cm[1,1])\n",
    "    recall = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    precision = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "    f1_score = 2 * (precision*recall) / (precision+recall)\n",
    "    \n",
    "    score_array = np.array([round(accuracy,6), round(error_rate,6), round(specificity,6), round(recall,6), round(precision,6), round(f1_score,6)])\n",
    "    \n",
    "    return score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score = evaluation_score(log_cm)\n",
    "tree_score = evaluation_score(tree_cm)\n",
    "forest_score = evaluation_score(forest_cm)\n",
    "ada_score = evaluation_score(ada_cm)\n",
    "lgbm_score = evaluation_score(lgbm_cm)\n",
    "cat_score = evaluation_score(cat_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.943236</td>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.972039</td>\n",
       "      <td>0.923685</td>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.950946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.992934</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.988966</td>\n",
       "      <td>0.996066</td>\n",
       "      <td>0.991331</td>\n",
       "      <td>0.993693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.959096</td>\n",
       "      <td>0.040904</td>\n",
       "      <td>0.980638</td>\n",
       "      <td>0.943901</td>\n",
       "      <td>0.985738</td>\n",
       "      <td>0.964366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>0.976479</td>\n",
       "      <td>0.962851</td>\n",
       "      <td>0.982103</td>\n",
       "      <td>0.972382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbgm</th>\n",
       "      <td>0.997645</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.996365</td>\n",
       "      <td>0.997899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.998351</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997064</td>\n",
       "      <td>0.998530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  error_rate  specificity    recall  precision  f1_score\n",
       "log     0.943236    0.056764     0.972039  0.923685   0.979866  0.950946\n",
       "tree    0.992934    0.007066     0.988966  0.996066   0.991331  0.993693\n",
       "forest  0.959096    0.040904     0.980638  0.943901   0.985738  0.964366\n",
       "ada     0.968674    0.031326     0.976479  0.962851   0.982103  0.972382\n",
       "lbgm    0.997645    0.002355     0.995363  0.999439   0.996365  0.997899\n",
       "cat     0.998351    0.001649     0.996254  1.000000   0.997064  0.998530"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = pd.DataFrame([log_score, tree_score, forest_score, ada_score, lgbm_score, cat_score], \n",
    "                        columns = ['accuracy', 'error_rate', 'specificity', 'recall', 'precision', 'f1_score'],\n",
    "                       index = ['log', 'tree', 'forest', 'ada', 'lbgm', 'cat'])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lbgmboosting과 catboosting의 결과가 가장 좋으므로 lbgm과 cat boosting의 예측값을 이용해 xgboost에 fit해  \n",
    "최종 stacking model을 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12737)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([lgbm_y_pred, cat_y_pred])\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12737, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.transpose(new_data)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7140,   12],\n",
       "       [   4, 5581]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbc = xgb.XGBClassifier(random_state=42, n_estimators = 100, max_depth = 5)\n",
    "xgbc.fit(new_data, y_test)\n",
    "xg_y_pred = xgbc.predict(new_data)\n",
    "\n",
    "xgbc_cm = confusion_matrix(y_test, xg_y_pred)\n",
    "xgbc_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xg</th>\n",
       "      <td>0.998744</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.997854</td>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.998322</td>\n",
       "      <td>0.998881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  error_rate  specificity   recall  precision  f1_score\n",
       "xg  0.998744    0.001256     0.997854  0.99944   0.998322  0.998881"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_score = evaluation_score(xgbc_cm)\n",
    "\n",
    "df_score = pd.DataFrame([xg_score], \n",
    "                        columns = ['accuracy', 'error_rate', 'specificity', 'recall', 'precision', 'f1_score'],\n",
    "                       index = ['xg'])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacking 이후 recall값만 catboost에 비해 조금 하락했을 뿐 다른 모든 지표에서 상승된 모습을 보여주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
